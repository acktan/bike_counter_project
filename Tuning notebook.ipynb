{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f35c90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "__file__ = Path('submissions') /  'my_submission1' /  'estimator.py'\n",
    "\n",
    "def _encode(X):\n",
    "    #cyclical encoding of dates\n",
    "    X = X.copy()\n",
    "    year_norm = 2 * np.pi * X['date'].dt.year / X['date'].dt.year.max()\n",
    "    month_norm = 2 * np.pi * X['date'].dt.month / X['date'].dt.month.max()\n",
    "    day_norm = 2 * np.pi * X['date'].dt.day / X['date'].dt.day.max()\n",
    "    weekday_norm = 2 * np.pi * X['date'].dt.weekday / X['date'].dt.weekday.max()\n",
    "    hour_norm = 2 * np.pi * X['date'].dt.hour / X['date'].dt.hour.max()\n",
    "    X.loc[:, 'year_sin'] = np.sin(year_norm)\n",
    "    X.loc[:, 'year_cos'] = np.cos(year_norm)\n",
    "    X.loc[:, 'month_sin'] = np.sin(month_norm)\n",
    "    X.loc[:, 'month_cos'] = np.cos(month_norm)\n",
    "    X.loc[:, 'day_sin'] = np.sin(day_norm)\n",
    "    X.loc[:, 'day_cos'] = np.cos(day_norm)\n",
    "    X.loc[:, 'weekday_sin'] = np.sin(weekday_norm)\n",
    "    X.loc[:, 'weekday_cos'] = np.cos(weekday_norm)\n",
    "    X.loc[:, 'hour_sin'] = np.sin(hour_norm)\n",
    "    X.loc[:, 'hour_cos'] = np.cos(hour_norm)\n",
    "    #encode dates\n",
    "    X.loc[:, 'year'] = X['date'].dt.year\n",
    "    X.loc[:, 'month'] = X['date'].dt.month\n",
    "    X.loc[:, 'day'] = X['date'].dt.day\n",
    "    X.loc[:, 'weekday'] = X['date'].dt.weekday\n",
    "    X.loc[:, 'hour'] = X['date'].dt.hour\n",
    "    return X.drop(columns=[\"date\"]) \n",
    "\n",
    "\n",
    "def _merge_external_data(X):\n",
    "    file_path = Path(__file__).parent / 'external_data.csv'\n",
    "    df_ext = pd.read_csv(file_path, parse_dates=['date'])\n",
    "    X = X.copy()\n",
    "    # When using merge_asof left frame need to be sorted\n",
    "    X['orig_index'] = np.arange(X.shape[0])\n",
    "    X = pd.merge_asof(X.sort_values('date'), df_ext[['date', 't', 'ff', 'u', 'brent', 'holidays', 'curfew']].sort_values('date'), on='date')\n",
    "    # Sort back to the original order\n",
    "    X = X.sort_values('orig_index')\n",
    "    del X['orig_index']\n",
    "    return X\n",
    "\n",
    "def get_estimator():\n",
    "    date_encoder = FunctionTransformer(_encode)\n",
    "    cycl_cols = ['month_sin', 'month_cos','day_sin', 'day_cos', 'weekday_sin', 'weekday_cos', 'hour_sin', 'hour_cos']\n",
    "    date_cols = ['year', 'day']\n",
    "\n",
    "    categorical_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    categorical_cols = [\"site_name\", \"counter_name\"]\n",
    "    holiday_cols =  ['curfew']\n",
    "    #numeric_cols = ['brent']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            ('date', 'passthrough', date_cols),\n",
    "            ('cycl', 'passthrough', cycl_cols),\n",
    "            ('holiday', 'passthrough', holiday_cols),\n",
    "            ('cat', categorical_encoder, categorical_cols)\n",
    "            #('numeric', 'passthrough', numeric_cols)\n",
    "        ]\n",
    "    )\n",
    "    regressor = HistGradientBoostingRegressor(random_state=0, max_leaf_nodes=275)\n",
    "\n",
    "    pipe = make_pipeline(\n",
    "        FunctionTransformer(_merge_external_data, validate=False), date_encoder, preprocessor, regressor)\n",
    "\n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac7b3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import problem\n",
    "\n",
    "X_train, y_train = problem.get_train_data()\n",
    "X_test, y_test = problem.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ad3b293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n",
      "steps\n",
      "verbose\n",
      "functiontransformer-1\n",
      "functiontransformer-2\n",
      "columntransformer\n",
      "histgradientboostingregressor\n",
      "functiontransformer-1__accept_sparse\n",
      "functiontransformer-1__check_inverse\n",
      "functiontransformer-1__func\n",
      "functiontransformer-1__inv_kw_args\n",
      "functiontransformer-1__inverse_func\n",
      "functiontransformer-1__kw_args\n",
      "functiontransformer-1__validate\n",
      "functiontransformer-2__accept_sparse\n",
      "functiontransformer-2__check_inverse\n",
      "functiontransformer-2__func\n",
      "functiontransformer-2__inv_kw_args\n",
      "functiontransformer-2__inverse_func\n",
      "functiontransformer-2__kw_args\n",
      "functiontransformer-2__validate\n",
      "columntransformer__n_jobs\n",
      "columntransformer__remainder\n",
      "columntransformer__sparse_threshold\n",
      "columntransformer__transformer_weights\n",
      "columntransformer__transformers\n",
      "columntransformer__verbose\n",
      "columntransformer__verbose_feature_names_out\n",
      "columntransformer__date\n",
      "columntransformer__cycl\n",
      "columntransformer__holiday\n",
      "columntransformer__cat\n",
      "columntransformer__cat__categories\n",
      "columntransformer__cat__dtype\n",
      "columntransformer__cat__handle_unknown\n",
      "columntransformer__cat__unknown_value\n",
      "histgradientboostingregressor__categorical_features\n",
      "histgradientboostingregressor__early_stopping\n",
      "histgradientboostingregressor__l2_regularization\n",
      "histgradientboostingregressor__learning_rate\n",
      "histgradientboostingregressor__loss\n",
      "histgradientboostingregressor__max_bins\n",
      "histgradientboostingregressor__max_depth\n",
      "histgradientboostingregressor__max_iter\n",
      "histgradientboostingregressor__max_leaf_nodes\n",
      "histgradientboostingregressor__min_samples_leaf\n",
      "histgradientboostingregressor__monotonic_cst\n",
      "histgradientboostingregressor__n_iter_no_change\n",
      "histgradientboostingregressor__random_state\n",
      "histgradientboostingregressor__scoring\n",
      "histgradientboostingregressor__tol\n",
      "histgradientboostingregressor__validation_fraction\n",
      "histgradientboostingregressor__verbose\n",
      "histgradientboostingregressor__warm_start\n"
     ]
    }
   ],
   "source": [
    "for param_name in get_estimator().get_params().keys():\n",
    "    print(param_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec69a2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165.1913046836853\n",
      "The best set of parameters is: {'histgradientboostingregressor__max_depth': 3, 'histgradientboostingregressor__max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "param_grid = {'histgradientboostingregressor__max_iter': (10, 100, 200),\n",
    "             'histgradientboostingregressor__max_depth': (3, 30, 60)}\n",
    "\n",
    "model_grid = GridSearchCV(get_estimator(), param_grid=param_grid, n_jobs=7)\n",
    "start_time = time.time()\n",
    "model_grid.fit(X_train, y_train)\n",
    "print(time.time() - start_time)\n",
    "\n",
    "print(f\"The best set of parameters is: {model_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5397129",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '“' (U+201C) (Temp/ipykernel_19768/4274756130.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ckunt\\AppData\\Local\\Temp/ipykernel_19768/4274756130.py\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    print(“TRAIN:”, train_index, “TEST:”, test_index) X_train, X_test = X[train_index], X[test_index]\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '“' (U+201C)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit()\n",
    "TimeSeriesSplit(max_train_size=None, n_splits=3)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(“TRAIN:”, train_index, “TEST:”, test_index) X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a6c775c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy score is: 0.56 +- 0.11\n",
      "The different scores obtained are: \n",
      "[0.56062665 0.70574582 0.58571728 0.58393854 0.35100386]\n",
      "The validation accuracy score is: 0.52 +- 0.07\n",
      "The different scores obtained are: \n",
      "[0.55676324 0.63239756 0.4270575  0.50191016 0.49208823]\n",
      "The best set of parameters is: {'histgradientboostingregressor__learning_rate': 0.1, 'histgradientboostingregressor__max_leaf_nodes': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train_scores = cross_val_score(model_grid, X_train, y_train)\n",
    "test_scores = cross_val_score(model_grid, X_test, y_test)\n",
    "\n",
    "print(f\"The train accuracy score is: {train_scores.mean():.2f} +- {train_scores.std():.2f}\")\n",
    "print(f\"The different scores obtained are: \\n{train_scores}\")\n",
    "\n",
    "print(f\"The test accuracy score is: {test_scores.mean():.2f} +- {test_scores.std():.2f}\")\n",
    "print(f\"The different scores obtained are: \\n{test_scores}\")\n",
    "\n",
    "print(f\"The best set of parameters is: {model_grid.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
