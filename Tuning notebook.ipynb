{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35c90bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HistGradientBoostingRegressor' from 'sklearn.ensemble' (C:\\Users\\ckunt\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-188c0f05a11a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHistGradientBoostingRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#__file__ = Path('submissions') /  'my_submission1' /  'estimator.py'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'HistGradientBoostingRegressor' from 'sklearn.ensemble' (C:\\Users\\ckunt\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#histgradboost\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "#__file__ = Path('submissions') /  'my_submission1' /  'estimator.py'\n",
    "\n",
    "def _encode(X):\n",
    "    #cyclical encoding of dates\n",
    "    X = X.copy()\n",
    "    year_norm = 2 * np.pi * X['date'].dt.year / X['date'].dt.year.max()\n",
    "    month_norm = 2 * np.pi * X['date'].dt.month / X['date'].dt.month.max()\n",
    "    day_norm = 2 * np.pi * X['date'].dt.day / X['date'].dt.day.max()\n",
    "    weekday_norm = 2 * np.pi * X['date'].dt.weekday / X['date'].dt.weekday.max()\n",
    "    hour_norm = 2 * np.pi * X['date'].dt.hour / X['date'].dt.hour.max()\n",
    "    X.loc[:, 'year_sin'] = np.sin(year_norm)\n",
    "    X.loc[:, 'year_cos'] = np.cos(year_norm)\n",
    "    X.loc[:, 'month_sin'] = np.sin(month_norm)\n",
    "    X.loc[:, 'month_cos'] = np.cos(month_norm)\n",
    "    X.loc[:, 'day_sin'] = np.sin(day_norm)\n",
    "    X.loc[:, 'day_cos'] = np.cos(day_norm)\n",
    "    X.loc[:, 'weekday_sin'] = np.sin(weekday_norm)\n",
    "    X.loc[:, 'weekday_cos'] = np.cos(weekday_norm)\n",
    "    X.loc[:, 'hour_sin'] = np.sin(hour_norm)\n",
    "    X.loc[:, 'hour_cos'] = np.cos(hour_norm)\n",
    "    #encode dates\n",
    "    X.loc[:, 'year'] = X['date'].dt.year\n",
    "    X.loc[:, 'month'] = X['date'].dt.month\n",
    "    X.loc[:, 'day'] = X['date'].dt.day\n",
    "    X.loc[:, 'weekday'] = X['date'].dt.weekday\n",
    "    X.loc[:, 'hour'] = X['date'].dt.hour\n",
    "    return X.drop(columns=[\"date\"]) \n",
    "\n",
    "def _merge_external_data(X):\n",
    "    file_path = Path(__file__).parent / 'external_data.csv'\n",
    "    df_ext = pd.read_csv(file_path, parse_dates=['date'])\n",
    "    X = X.copy()\n",
    "    # When using merge_asof left frame need to be sorted\n",
    "    X['orig_index'] = np.arange(X.shape[0])\n",
    "    X = pd.merge_asof(X.sort_values('date'), df_ext[['date', 't', 'ff', 'u', 'brent', 'holidays', 'curfew', 'rush hour', 'Taux', 'bike']].sort_values('date'), on='date')\n",
    "    # Sort back to the original order\n",
    "    X = X.sort_values('orig_index')\n",
    "    del X['orig_index']\n",
    "    return X\n",
    "\n",
    "def get_estimator():\n",
    "    date_encoder = FunctionTransformer(_encode)\n",
    "    cycl_cols = ['month_sin', 'month_cos','day_sin', 'day_cos', 'weekday_sin', 'weekday_cos', 'hour_sin', 'hour_cos']\n",
    "    date_cols = ['year', 'day']\n",
    "\n",
    "    categorical_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    categorical_cols = [\"site_name\", \"counter_name\"]\n",
    "    binary_cols =  ['curfew']\n",
    "    numeric_cols = ['Taux', 'bike', 't', 'brent', 'ff']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            ('date', 'passthrough', date_cols),\n",
    "            ('cycl', 'passthrough', cycl_cols),\n",
    "            ('holiday', 'passthrough', binary_cols),\n",
    "            ('cat', categorical_encoder, categorical_cols),\n",
    "            ('numeric', 'passthrough', numeric_cols)\n",
    "        ]\n",
    "    )\n",
    "    regressor = HistGradientBoostingRegressor(random_state=0, max_leaf_nodes=300, max_iter=150)\n",
    "\n",
    "    pipe = make_pipeline(\n",
    "        FunctionTransformer(_merge_external_data, validate=False), date_encoder, preprocessor, regressor)\n",
    "\n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import problem\n",
    "\n",
    "X_train, y_train = problem.get_train_data()\n",
    "X_test, y_test = problem.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3b293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for param_name in get_estimator().get_params().keys():\n",
    "    print(param_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec69a2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165.1913046836853\n",
      "The best set of parameters is: {'histgradientboostingregressor__max_depth': 3, 'histgradientboostingregressor__max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "param_grid = {'histgradientboostingregressor__max_leaf_nodes': (10, 100, 300),\n",
    "             'histgradientboostingregressor__max_iter': (3, 30, 60, 100)}\n",
    "\n",
    "model_grid = GridSearchCV(get_estimator(), param_grid=param_grid, n_jobs=7)\n",
    "start_time = time.time()\n",
    "model_grid.fit(X_train, y_train)\n",
    "print(time.time() - start_time)\n",
    "\n",
    "print(f\"The best set of parameters is: {model_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a32b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "param_search = {'histgradientboostingregressor__max_leaf_nodes': (10, 100, 300, 600),\n",
    "             'histgradientboostingregressor__max_depth': (3, 30, 60, 100, 200, 300)}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=6)\n",
    "gsearch = GridSearchCV(estimator=get_estimator(), cv=tscv,\n",
    "                        param_grid=param_search)\n",
    "gsearch.fit(X_train, y_train)\n",
    "print(f\"The best set of parameters is: {gsearch.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a6c775c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy score is: 0.56 +- 0.11\n",
      "The different scores obtained are: \n",
      "[0.56062665 0.70574582 0.58571728 0.58393854 0.35100386]\n",
      "The validation accuracy score is: 0.52 +- 0.07\n",
      "The different scores obtained are: \n",
      "[0.55676324 0.63239756 0.4270575  0.50191016 0.49208823]\n",
      "The best set of parameters is: {'histgradientboostingregressor__learning_rate': 0.1, 'histgradientboostingregressor__max_leaf_nodes': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train_scores = cross_val_score(model_grid, X_train, y_train)\n",
    "test_scores = cross_val_score(model_grid, X_test, y_test)\n",
    "\n",
    "print(f\"The train accuracy score is: {train_scores.mean():.2f} +- {train_scores.std():.2f}\")\n",
    "print(f\"The different scores obtained are: \\n{train_scores}\")\n",
    "\n",
    "print(f\"The test accuracy score is: {test_scores.mean():.2f} +- {test_scores.std():.2f}\")\n",
    "print(f\"The different scores obtained are: \\n{test_scores}\")\n",
    "\n",
    "print(f\"The best set of parameters is: {model_grid.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
