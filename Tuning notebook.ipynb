{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f35c90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "__file__ = Path('submissions') /  'external_data' /  'estimator.py'\n",
    "\n",
    "def _encode(X):\n",
    "    #cyclical encoding of dates\n",
    "    X = X.copy()\n",
    "    year_norm = 2 * math.pi * X['date'].dt.year / X['date'].dt.year.max()\n",
    "    month_norm = 2 * math.pi * X['date'].dt.month / X['date'].dt.month.max()\n",
    "    day_norm = 2 * math.pi * X['date'].dt.day / X['date'].dt.day.max()\n",
    "    weekday_norm = 2 * math.pi * X['date'].dt.weekday / X['date'].dt.weekday.max()\n",
    "    hour_norm = 2 * math.pi * X['date'].dt.hour / X['date'].dt.hour.max()\n",
    "    X.loc[:, 'year_sin'] = np.sin(year_norm)\n",
    "    X.loc[:, 'year_cos'] = np.cos(year_norm)\n",
    "    X.loc[:, 'month_sin'] = np.sin(month_norm)\n",
    "    X.loc[:, 'month_cos'] = np.cos(month_norm)\n",
    "    X.loc[:, 'day_sin'] = np.sin(day_norm)\n",
    "    X.loc[:, 'day_cos'] = np.cos(day_norm)\n",
    "    X.loc[:, 'weekday_sin'] = np.sin(weekday_norm)\n",
    "    X.loc[:, 'weekday_cos'] = np.cos(weekday_norm)\n",
    "    X.loc[:, 'hour_sin'] = np.sin(hour_norm)\n",
    "    X.loc[:, 'hour_cos'] = np.cos(hour_norm)\n",
    "    #encode dates\n",
    "    X.loc[:, 'year'] = X['date'].dt.year\n",
    "    X.loc[:, 'month'] = X['date'].dt.month\n",
    "    X.loc[:, 'day'] = X['date'].dt.day\n",
    "    X.loc[:, 'weekday'] = X['date'].dt.weekday\n",
    "    X.loc[:, 'hour'] = X['date'].dt.hour\n",
    "    return X\n",
    "\n",
    "\n",
    "def _merge_external_data(X):\n",
    "    file_path = Path(__file__).parent / 'external_data.csv'\n",
    "    df_ext = pd.read_csv(file_path, parse_dates=['date'])\n",
    "    X = X.copy()\n",
    "    # When using merge_asof left frame need to be sorted\n",
    "    X['orig_index'] = np.arange(X.shape[0])\n",
    "    X = pd.merge_asof(X.sort_values('date'), df_ext[['date', 't', 'ff', 'u', 'brent', 'vacances_scol', 'bank_hol']].sort_values('date'), on='date')\n",
    "    # Sort back to the original order\n",
    "    X = X.sort_values('orig_index')\n",
    "    del X['orig_index']\n",
    "    return X\n",
    "    # Finally we can drop the original columns from the dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32e88fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator():\n",
    "    date_encoder = FunctionTransformer(_encode)\n",
    "    cycl_cols = ['month_sin', 'month_cos', 'day_sin', 'day_cos', 'weekday_sin', 'weekday_cos', 'hour_sin', 'hour_cos']\n",
    "\n",
    "    categorical_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    categorical_cols = [\"site_name\", \"counter_name\"]\n",
    "    holiday_cols =  ['bank_hol', 'vacances_scol']\n",
    "    numeric_cols = ['t', 'ff', 'u', 'brent']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            ('date', 'passthrough', cycl_cols),\n",
    "            ('year', 'passthrough', ['year']),\n",
    "            ('holiday', 'passthrough', holiday_cols),\n",
    "            ('cat', categorical_encoder, categorical_cols),\n",
    "            ('numeric', 'passthrough', numeric_cols)\n",
    "        ]\n",
    "    )\n",
    "    regressor = HistGradientBoostingRegressor(random_state=0)\n",
    "\n",
    "    pipe = make_pipeline(\n",
    "        FunctionTransformer(_merge_external_data, validate=False), date_encoder, preprocessor, regressor)\n",
    "\n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac7b3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import problem\n",
    "\n",
    "X_train, y_train = problem.get_train_data()\n",
    "X_test, y_test = problem.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ad3b293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n",
      "steps\n",
      "verbose\n",
      "functiontransformer-1\n",
      "functiontransformer-2\n",
      "columntransformer\n",
      "histgradientboostingregressor\n",
      "functiontransformer-1__accept_sparse\n",
      "functiontransformer-1__check_inverse\n",
      "functiontransformer-1__func\n",
      "functiontransformer-1__inv_kw_args\n",
      "functiontransformer-1__inverse_func\n",
      "functiontransformer-1__kw_args\n",
      "functiontransformer-1__validate\n",
      "functiontransformer-2__accept_sparse\n",
      "functiontransformer-2__check_inverse\n",
      "functiontransformer-2__func\n",
      "functiontransformer-2__inv_kw_args\n",
      "functiontransformer-2__inverse_func\n",
      "functiontransformer-2__kw_args\n",
      "functiontransformer-2__validate\n",
      "columntransformer__n_jobs\n",
      "columntransformer__remainder\n",
      "columntransformer__sparse_threshold\n",
      "columntransformer__transformer_weights\n",
      "columntransformer__transformers\n",
      "columntransformer__verbose\n",
      "columntransformer__verbose_feature_names_out\n",
      "columntransformer__date\n",
      "columntransformer__year\n",
      "columntransformer__holiday\n",
      "columntransformer__cat\n",
      "columntransformer__numeric\n",
      "columntransformer__cat__categories\n",
      "columntransformer__cat__dtype\n",
      "columntransformer__cat__handle_unknown\n",
      "columntransformer__cat__unknown_value\n",
      "histgradientboostingregressor__categorical_features\n",
      "histgradientboostingregressor__early_stopping\n",
      "histgradientboostingregressor__l2_regularization\n",
      "histgradientboostingregressor__learning_rate\n",
      "histgradientboostingregressor__loss\n",
      "histgradientboostingregressor__max_bins\n",
      "histgradientboostingregressor__max_depth\n",
      "histgradientboostingregressor__max_iter\n",
      "histgradientboostingregressor__max_leaf_nodes\n",
      "histgradientboostingregressor__min_samples_leaf\n",
      "histgradientboostingregressor__monotonic_cst\n",
      "histgradientboostingregressor__n_iter_no_change\n",
      "histgradientboostingregressor__random_state\n",
      "histgradientboostingregressor__scoring\n",
      "histgradientboostingregressor__tol\n",
      "histgradientboostingregressor__validation_fraction\n",
      "histgradientboostingregressor__verbose\n",
      "histgradientboostingregressor__warm_start\n"
     ]
    }
   ],
   "source": [
    "for param_name in get_estimator().get_params().keys():\n",
    "    print(param_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec69a2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167.5158176422119\n",
      "The best set of parameters is: {'histgradientboostingregressor__learning_rate': 0.1, 'histgradientboostingregressor__max_leaf_nodes': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "param_grid = {'histgradientboostingregressor__learning_rate': (0.01, 0.1, 1, 10),\n",
    "             'histgradientboostingregressor__max_leaf_nodes': (3, 10, 30)}\n",
    "\n",
    "model_grid = GridSearchCV(get_estimator(), param_grid=param_grid, n_jobs=7)\n",
    "start_time = time.time()\n",
    "model_grid.fit(X_train, y_train)\n",
    "print(time.time() - start_time)\n",
    "\n",
    "print(f\"The best set of parameters is: {model_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a6c775c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy score is: 0.56 +- 0.11\n",
      "The different scores obtained are: \n",
      "[0.56062665 0.70574582 0.58571728 0.58393854 0.35100386]\n",
      "The validation accuracy score is: 0.52 +- 0.07\n",
      "The different scores obtained are: \n",
      "[0.55676324 0.63239756 0.4270575  0.50191016 0.49208823]\n",
      "The best set of parameters is: {'histgradientboostingregressor__learning_rate': 0.1, 'histgradientboostingregressor__max_leaf_nodes': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train_scores = cross_val_score(model_grid, X_train, y_train)\n",
    "test_scores = cross_val_score(model_grid, X_test, y_test)\n",
    "\n",
    "print(f\"The train accuracy score is: {train_scores.mean():.2f} +- {train_scores.std():.2f}\")\n",
    "print(f\"The different scores obtained are: \\n{train_scores}\")\n",
    "\n",
    "print(f\"The test accuracy score is: {test_scores.mean():.2f} +- {test_scores.std():.2f}\")\n",
    "print(f\"The different scores obtained are: \\n{test_scores}\")\n",
    "\n",
    "print(f\"The best set of parameters is: {model_grid.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
